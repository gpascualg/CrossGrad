{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMDB Loading won't be available\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from SenseTheFlow import config\n",
    "config.bar = tqdm.tqdm_notebook\n",
    "\n",
    "from SenseTheFlow.model import Model, CustomSummarySaverHook, DataParser, EvalCallback\n",
    "from SenseTheFlow import rocksdb\n",
    "from SenseTheFlow.dataset import Dataset, CustomLoader\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "import random\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "def train_generator():\n",
    "    images, labels = mnist.train_images(), mnist.train_labels()\n",
    "    for i in range(images.shape[0]):\n",
    "        img, label = images[i, :, :, np.newaxis], labels[i]\n",
    "        img = img.astype(np.float32)\n",
    "        cls = random.randint(0, 1)\n",
    "        \n",
    "        if cls == 1:\n",
    "            img = rotate(img, 15, reshape=False)\n",
    "            \n",
    "        yield (img, {'label': [int(label)], 'cls': [int(cls)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossgrad_latent_fn(features, labels, mode, params):\n",
    "    # Some convolutions\n",
    "    features = tf.layers.conv2d(features, 32, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.conv2d(features, 32, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.max_pooling2d(features, 2, 1, data_format=params['data_format'])\n",
    "    features = tf.layers.conv2d(features, 128, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.conv2d(features, 128, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.max_pooling2d(features, 2, 1, data_format=params['data_format'])\n",
    "    features = tf.layers.conv2d(features, 256, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.conv2d(features, 256, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    \n",
    "    # Down to [batch, 1, 1, 256] -> [batch, 1, 1, 256]\n",
    "    size = features.shape.as_list()[2]\n",
    "    features = tf.layers.max_pooling2d(features, size, 1, data_format=params['data_format'])\n",
    "\n",
    "    # Target dimensions [batch, 1, 1, target] -> [batch, target]\n",
    "    features = tf.layers.conv2d(features, params['latent_space_dimensions'], 1, data_format=params['data_format'])\n",
    "    features = tf.layers.flatten(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossgrad_domain_fn(features, labels, mode, params):\n",
    "    # Compute logits\n",
    "    features = tf.layers.dense(features, params['latent_space_dimensions'], activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(features, params['num_domain'])\n",
    "    \n",
    "    # Final classification\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    domain = tf.argmax(softmax, axis=-1)\n",
    "    \n",
    "    # During inference we don't have labels\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.one_hot(labels, params['num_domain']),\n",
    "            logits=logits\n",
    "        )\n",
    "    \n",
    "    return domain, tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossgrad(mode, label_fn, x, domain, labels, epsilon_d, epsilon_l, alpha_d, alpha_l, latent_fn=None, domain_fn=None, latent_space_dimensions=100, params=None):    \n",
    "    # Some default parameters\n",
    "    if params == None: params = {}        \n",
    "    params['latent_space_dimensions'] = latent_space_dimensions\n",
    "    if 'data_format' not in params or params['data_format'] is None:\n",
    "        params['data_format'] = detect_data_format()\n",
    "    \n",
    "    # Given functions or default\n",
    "    latent_fn = latent_fn or crossgrad_latent_fn\n",
    "    domain_fn = domain_fn or crossgrad_domain_fn\n",
    "    \n",
    "    # To expected data format\n",
    "    x = to_data_format(x, 'channels_last', params['data_format'])\n",
    "    \n",
    "    def forward(x_l, x_d, d, labels, mode, params):\n",
    "        latent = latent_fn(features=x_l, labels=None, mode=mode, params=params)\n",
    "        domain, loss_domain = domain_fn(features=latent, labels=d, mode=mode, params=params)\n",
    "        outputs, loss_label = label_fn(features=x_d, latent=latent, labels=labels, mode=mode, params=params)\n",
    "\n",
    "        return ((domain, loss_domain), (outputs, loss_label))\n",
    "    \n",
    "    # First forward pass\n",
    "    ((d1, d1_loss), (l1, l1_loss)) = forward(x, x, domain, labels, mode, params)\n",
    "    grad_label_x = tf.gradients(l1_loss, x)[0]\n",
    "    grad_domain_x = tf.gradients(d1_loss, x)[0]\n",
    "    \n",
    "    tf.summary.scalar('loss/domain/1', d1_loss)\n",
    "    tf.summary.scalar('loss/labels/1', l1_loss)\n",
    "        \n",
    "    # Second pass\n",
    "    x_d = x + epsilon_d * grad_domain_x\n",
    "    x_l = x + epsilon_l * grad_label_x\n",
    "    ((d2, d2_loss), (l2, l2_loss)) = forward(x_l, x_d, domain, labels, mode, params)\n",
    "    \n",
    "    tf.summary.scalar('loss/domain/2', d2_loss)\n",
    "    tf.summary.scalar('loss/labels/2', l2_loss)    \n",
    "    \n",
    "    tf.summary.image('x', to_data_format(x, params['data_format'], 'channels_last'))\n",
    "    tf.summary.image('x_d', to_data_format(x_d, params['data_format'], 'channels_last'))\n",
    "    tf.summary.image('x_l', to_data_format(x_l, params['data_format'], 'channels_last'))\n",
    "    \n",
    "    l_total_loss = (1 - alpha_l) * l1_loss + alpha_l * l2_loss\n",
    "    d_total_loss = (1 - alpha_d) * d1_loss + alpha_d * d2_loss\n",
    "    predictions = {\n",
    "        'd1': d1,\n",
    "        'd2': d2,\n",
    "        'l1': l1,\n",
    "        'l2': l2\n",
    "    }\n",
    "    return predictions, l_total_loss + d_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fn(features, latent, labels, mode, params):\n",
    "    features = tf.layers.conv2d(features, 32, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.conv2d(features, 64, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.max_pooling2d(features, 2, 1, data_format=params['data_format'])\n",
    "    features = tf.layers.flatten(features)\n",
    "    features = tf.layers.dense(features, params['latent_space_dimensions'], activation=tf.nn.relu)\n",
    "    features = tf.concat((features, latent), axis=-1)\n",
    "    features = tf.layers.dense(features, params['latent_space_dimensions'], activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(features, params['num_classes'])\n",
    "    \n",
    "    # Final classification\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    cls = tf.argmax(softmax, axis=-1)\n",
    "    \n",
    "    # During inference we don't have labels\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.one_hot(labels, params['num_classes']),\n",
    "            logits=logits\n",
    "        )\n",
    "    \n",
    "    return cls, tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    with tf.device('/gpu:1'):\n",
    "        predictions, loss = crossgrad(mode, label_fn, features, labels['cls'], labels['label'], 2.0, 2.0, 0.2, 0.2, params=params)\n",
    "                \n",
    "        accuracy_d1 = tf.metrics.accuracy(predictions['d1'], labels['cls'])\n",
    "        accuracy_l1 = tf.metrics.accuracy(predictions['l1'], labels['label'])\n",
    "        tf.summary.scalar('metrics/epoch/accuracy/domain/1', accuracy_d1[1])\n",
    "        tf.summary.scalar('metrics/epoch/accuracy/labels/1', accuracy_l1[1])\n",
    "        \n",
    "        accuracy_d2 = tf.metrics.accuracy(predictions['d2'], labels['cls'])\n",
    "        accuracy_l2 = tf.metrics.accuracy(predictions['l2'], labels['label'])\n",
    "        tf.summary.scalar('metrics/epoch/accuracy/domain/2', accuracy_d2[1])\n",
    "        tf.summary.scalar('metrics/epoch/accuracy/labels/2', accuracy_l2[1])\n",
    "        \n",
    "        \n",
    "        # Fetch global step\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "        tf.summary.scalar('global_step/step', global_step)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "\n",
    "            # Batch norm requires update_ops to be added as a train_op dependency.\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops + [accuracy_d1[0], accuracy_l1[0], accuracy_d2[0], accuracy_l2[0]]):\n",
    "                train_op = optimizer.minimize(loss, global_step)\n",
    "        else:\n",
    "            train_op = None\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops={\n",
    "                'accuracy/domain/1': accuracy_d1, \n",
    "                'accuracy/labels/1': accuracy_l1,\n",
    "                'accuracy/domain/2': accuracy_d2, \n",
    "                'accuracy/labels/2': accuracy_l2\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12881bbd2ccb46cf862da55611c15450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834b3718e51a4b8293beb31cfae73605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0) {'label': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=int32>, 'cls': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int32>}\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "done\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "You have no `evaluation` dataset\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0) {'label': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=int32>, 'cls': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int32>}\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "done\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "You have no `evaluation` dataset\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0) {'label': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=int32>, 'cls': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int32>}\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "done\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "You have no `evaluation` dataset\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0) {'label': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=int32>, 'cls': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int32>}\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "done\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "You have no `evaluation` dataset\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0) {'label': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=int32>, 'cls': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int32>}\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "done\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "You have no `evaluation` dataset\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0) {'label': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=int32>, 'cls': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int32>}\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "done\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "You have no `evaluation` dataset\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0) {'label': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=int32>, 'cls': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int32>}\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "done\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "You have no `evaluation` dataset\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 28, 28, 1), dtype=float32, device=/device:CPU:0) {'label': <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=int32>, 'cls': <tf.Tensor 'IteratorGetNext:1' shape=(?, 1) dtype=int32>}\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "LOGITS_LABELS\n",
      "Tensor(\"dense_9/BiasAdd:0\", shape=(?, 10), dtype=float32, device=/device:GPU:1)\n",
      "done\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n",
      "Tensor(\"ArgMax:0\", shape=(?,), dtype=int64, device=/device:GPU:1)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 1), dtype=int32, device=/device:CPU:0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4ebb2f07e5fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     model.train(100, 2, eval_summary=[\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;34m'metrics/batch/accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics/epoch/accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics/epoch/miou'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     ])\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-libs/SenseTheFlow/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, epochs_per_eval, eval_callback, eval_log, eval_summary)\u001b[0m\n\u001b[1;32m    374\u001b[0m             self.classifier().train(\n\u001b[1;32m    375\u001b[0m                 \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__callbacks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1023\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'data_format': None,\n",
    "    'batch_size': 32,\n",
    "    'num_domain': 2,\n",
    "    'num_classes': 10\n",
    "}\n",
    "\n",
    "model_dir = '/data/storage/deepglobe/models/{}'.format('crossgrad')\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with Model(model_fn, model_dir, config=config, params=params, delete_existing=True) as model:\n",
    "    data_parser = DataParser()\n",
    "    data_parser.train_from_generator(\n",
    "        generator=train_generator,\n",
    "        output_types=(tf.float32, {'label': tf.int32, 'cls': tf.int32}),\n",
    "        output_shapes=([28, 28, 1], {'label': [1], 'cls': [1]}),\n",
    "        pre_shuffle=7,\n",
    "        post_shuffle=False,\n",
    "        flatten=False,\n",
    "        num_samples=None,\n",
    "        batch_size=params['batch_size']\n",
    "    )\n",
    "     \n",
    "    model.data(data_parser)\n",
    "    \n",
    "    model.train(100, 2, eval_summary=[\n",
    "        'metrics/batch/accuracy', 'metrics/epoch/accuracy', 'metrics/epoch/miou'\n",
    "    ])\n",
    "\n",
    "#     do_predict(model)\n",
    "#     do_train_pred(model)\n",
    "#     do_eval_pred(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
