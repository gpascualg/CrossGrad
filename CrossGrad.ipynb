{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMDB Loading won't be available\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from SenseTheFlow import config\n",
    "config.bar = tqdm.tqdm_notebook\n",
    "\n",
    "from SenseTheFlow.model import Model, DataParser\n",
    "from SenseTheFlow.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "import random\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "def mnist_generator(images_fn, labels_fn):\n",
    "    images, labels = images_fn(), labels_fn()\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        img, label = images[i, :, :, np.newaxis], labels[i]\n",
    "        img = img.astype(np.float32)\n",
    "        cls = random.randint(0, 1)\n",
    "        \n",
    "        if cls == 1:\n",
    "            img = rotate(img, 15, reshape=False)\n",
    "            \n",
    "        yield (img, {'label': [int(label)], 'cls': [int(cls)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fn(features, latent, labels, mode, params):\n",
    "    features = tf.layers.conv2d(features, 32, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.conv2d(features, 64, 3, data_format=params['data_format'], activation=tf.nn.relu)\n",
    "    features = tf.layers.max_pooling2d(features, 2, 1, data_format=params['data_format'])\n",
    "    features = tf.layers.flatten(features)\n",
    "    features = tf.layers.dense(features, params['latent_space_dimensions'], activation=tf.nn.relu)\n",
    "    features = tf.concat((features, latent), axis=-1)\n",
    "    features = tf.layers.dense(features, params['latent_space_dimensions'], activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(features, params['num_classes'])\n",
    "    \n",
    "    # Final classification\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    cls = tf.argmax(softmax, axis=-1)\n",
    "    \n",
    "    # During inference we don't have labels\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.one_hot(labels, params['num_classes']),\n",
    "            logits=logits\n",
    "        )\n",
    "    \n",
    "    return cls, tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crossgrad import *\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    with tf.device('/gpu:1'):\n",
    "        predictions, loss = crossgrad(mode, label_fn, features, labels['cls'], labels['label'], 10, 10, 0.5, 0.5, params=params)\n",
    "        \n",
    "        accuracy_d1 = tf.metrics.accuracy(predictions['d1'], labels['cls'])\n",
    "        accuracy_l1 = tf.metrics.accuracy(predictions['l1'], labels['label'])\n",
    "        \n",
    "        accuracy_d2 = tf.metrics.accuracy(predictions['d2'], labels['cls'])\n",
    "        accuracy_l2 = tf.metrics.accuracy(predictions['l2'], labels['label'])        \n",
    "        \n",
    "        # Fetch global step\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "        \n",
    "        if params.get('summaries'):\n",
    "            tf.summary.scalar('metrics/epoch/accuracy/domain/1', accuracy_d1[1])\n",
    "            tf.summary.scalar('metrics/epoch/accuracy/labels/1', accuracy_l1[1])\n",
    "\n",
    "            tf.summary.scalar('metrics/epoch/accuracy/domain/2', accuracy_d2[1])\n",
    "            tf.summary.scalar('metrics/epoch/accuracy/labels/2', accuracy_l2[1])\n",
    "            \n",
    "            tf.summary.scalar('global_step/step', global_step)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "\n",
    "            # Batch norm requires update_ops to be added as a train_op dependency.\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops + [accuracy_d1[0], accuracy_l1[0], accuracy_d2[0], accuracy_l2[0]]):\n",
    "                train_op = optimizer.minimize(loss, global_step)\n",
    "        else:\n",
    "            train_op = None\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops={\n",
    "                'accuracy/domain/1': accuracy_d1, \n",
    "                'accuracy/labels/1': accuracy_l1,\n",
    "                'accuracy/domain/2': accuracy_d2, \n",
    "                'accuracy/labels/2': accuracy_l2\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dbf5f908e947b0af759fa0814bde40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1abe705e61b42d2bb5ae3ef487e47ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ea10bd33504f9f8fe393dd5c33cf86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51ec153f45245798e029f40cc5ab2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2342e8b900e4142bf348c08b2def1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c723f265d68c476c8ffbd1e4a170bf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    'data_format': None,\n",
    "    'batch_size': 32,\n",
    "    'num_domain': 2,\n",
    "    'num_classes': 10,\n",
    "    'summaries': True\n",
    "}\n",
    "\n",
    "model_dir = '/data/storage/deepglobe/models/{}'.format('crossgrad')\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with Model(model_fn, model_dir, config=config, params=params, delete_existing=True) as model:\n",
    "    data_parser = DataParser()\n",
    "    data_parser.train_from_generator(\n",
    "        generator=lambda: mnist_generator(mnist.train_images, mnist.train_labels),\n",
    "        output_types=(tf.float32, {'label': tf.int32, 'cls': tf.int32}),\n",
    "        output_shapes=([28, 28, 1], {'label': [1], 'cls': [1]}),\n",
    "        batch_size=params['batch_size']\n",
    "    )\n",
    "    \n",
    "    data_parser.eval_from_generator(\n",
    "        generator=lambda: mnist_generator(mnist.test_images, mnist.test_labels),\n",
    "        output_types=(tf.float32, {'label': tf.int32, 'cls': tf.int32}),\n",
    "        output_shapes=([28, 28, 1], {'label': [1], 'cls': [1]}),\n",
    "        batch_size=params['batch_size']\n",
    "    )\n",
    "    \n",
    "    model.data(data_parser)\n",
    "    \n",
    "    model.train(100, 1, eval_summary=[\n",
    "        'metrics/epoch/accuracy/domain/1', 'metrics/epoch/accuracy/domain/2',\n",
    "        'metrics/epoch/accuracy/labels/1', 'metrics/epoch/accuracy/labels/2'\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
